{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2512eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec myenv in C:\\Users\\arman\\AppData\\Roaming\\jupyter\\kernels\\myenv\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72ca51",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 231\u001b[0m\n\u001b[0;32m    228\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 231\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 204\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# ایجاد و آموزش مدل\u001b[39;00m\n\u001b[0;32m    203\u001b[0m model \u001b[38;5;241m=\u001b[39m EnhancedLSTM(input_size\u001b[38;5;241m=\u001b[39mtrain_seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 204\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# ذخیره مدل نهایی\u001b[39;00m\n\u001b[0;32m    207\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m: scaler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     }\n\u001b[0;32m    214\u001b[0m }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 110\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(model, train_loader, test_loader):\n\u001b[0;32m    109\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m    113\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# تنظیمات\n",
    "SEED = 42\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# کلاس Dataset\n",
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.sequences[idx]),\n",
    "            torch.FloatTensor([self.targets[idx]]).squeeze()\n",
    "        )\n",
    "\n",
    "# مدل LSTM بهبود یافته\n",
    "class EnhancedLSTM(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze()\n",
    "\n",
    "# بارگذاری و پیش‌پردازش داده\n",
    "def load_and_preprocess(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "    df['datetime'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'])\n",
    "    df = df.drop(['<DATE>', '<TIME>'], axis=1)\n",
    "    df.columns = [col.strip('<>').lower() for col in df.columns]\n",
    "    df = df.set_index('datetime').sort_index()\n",
    "    \n",
    "    # محاسبه لگاریتم قیمت‌ها\n",
    "    df['log_close'] = np.log(df['close'])\n",
    "    \n",
    "    # ویژگی‌های فنی بر اساس لگاریتم قیمت\n",
    "    df['log_return'] = df['log_close'].diff()\n",
    "    df['volatility'] = df['log_return'].rolling(20).std().fillna(0)\n",
    "    df['price_change'] = df['log_close'].diff(5)\n",
    "    \n",
    "    # اندیکاتورهای تکنیکال\n",
    "    df.ta.ema(length=20, close='log_close', append=True)\n",
    "    df.ta.rsi(length=14, close='log_close', append=True)\n",
    "    \n",
    "    # حذف مقادیر نامعتبر\n",
    "    df = df.dropna().replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # هدف پیش‌بینی: تغییرات لگاریتمی قیمت\n",
    "    df['target'] = df['log_close'].shift(-1) - df['log_close']\n",
    "    \n",
    "    return df[['log_close', 'log_return', 'volatility', 'price_change', \n",
    "              'EMA_20', 'RSI_14', 'target']]\n",
    "\n",
    "# آماده‌سازی داده\n",
    "def prepare_data(df):\n",
    "    # نرمال‌سازی\n",
    "    features = df.drop(columns=['target'])\n",
    "    target = df['target']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # ایجاد دنباله‌ها\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(scaled_features)-SEQ_LENGTH):\n",
    "        sequences.append(scaled_features[i:i+SEQ_LENGTH])\n",
    "        targets.append(target.iloc[i+SEQ_LENGTH])\n",
    "    \n",
    "    return np.array(sequences), np.array(targets), scaler\n",
    "\n",
    "# آموزش مدل\n",
    "def train_model(model, train_loader, test_loader):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'rmse': [],\n",
    "        'r2': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # ارزیابی\n",
    "        model.eval()\n",
    "        test_loss, preds, truths = 0, [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                test_loss += criterion(outputs, labels).item()\n",
    "                preds.extend(outputs.numpy())\n",
    "                truths.extend(labels.numpy())\n",
    "        \n",
    "        # محاسبه معیارها\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        rmse = np.sqrt(mean_squared_error(truths, preds))\n",
    "        r2 = r2_score(truths, preds)\n",
    "        \n",
    "        # ذخیره تاریخچه\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['test_loss'].append(avg_test_loss)\n",
    "        history['rmse'].append(rmse)\n",
    "        history['r2'].append(r2)\n",
    "        \n",
    "        # چاپ گزارش\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}')\n",
    "        print(f'Train Loss: {avg_train_loss:.6f} | Test Loss: {avg_test_loss:.6f}')\n",
    "        print(f'RMSE: {rmse:.6f} | R²: {r2:.6f}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Early Stopping و تنظیم نرخ یادگیری\n",
    "        scheduler.step(avg_test_loss)\n",
    "        \n",
    "        if avg_test_loss < best_loss:\n",
    "            best_loss = avg_test_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= 10:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    return history\n",
    "\n",
    "# تابع اصلی\n",
    "def main():\n",
    "    # بارگذاری و پیش‌پردازش داده\n",
    "    df = load_and_preprocess('XAUUSD-I_M30.txt')\n",
    "    \n",
    "    # آماده‌سازی داده\n",
    "    sequences, targets, scaler = prepare_data(df)\n",
    "    \n",
    "    # تقسیم داده\n",
    "    train_size = int(0.8 * len(sequences))\n",
    "    train_seq, test_seq = sequences[:train_size], sequences[train_size:]\n",
    "    train_tgt, test_tgt = targets[:train_size], targets[train_size:]\n",
    "    \n",
    "    # ایجاد DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        PriceDataset(train_seq, train_tgt),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        PriceDataset(test_seq, test_tgt),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # ایجاد و آموزش مدل\n",
    "    model = EnhancedLSTM(input_size=train_seq.shape[2])\n",
    "    history = train_model(model, train_loader, test_loader)\n",
    "    \n",
    "    # ذخیره مدل نهایی\n",
    "    torch.save({\n",
    "        'model_state': model.state_dict(),\n",
    "        'scaler': scaler,\n",
    "        'config': {\n",
    "            'input_size': train_seq.shape[2],\n",
    "            'seq_length': SEQ_LENGTH\n",
    "        }\n",
    "    }, 'final_model.pth')\n",
    "    \n",
    "    # رسم نمودارها\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['test_loss'], label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['r2'], label='R² Score')\n",
    "    plt.legend()\n",
    "    plt.title('Model Performance')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
