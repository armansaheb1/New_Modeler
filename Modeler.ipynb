{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2512eedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec myenv in C:\\Users\\arman\\AppData\\Roaming\\jupyter\\kernels\\myenv\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72ca51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10896,1) into shape (10896,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 235\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# ایجاد و آموزش مدل\u001b[39;00m\n\u001b[0;32m    234\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMModel(input_size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 235\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 140\u001b[0m, in \u001b[0;36mtrain_and_report\u001b[1;34m(model, train_loader, test_loader, scaler)\u001b[0m\n\u001b[0;32m    137\u001b[0m     train_trues\u001b[38;5;241m.\u001b[39mextend(y\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# ارزیابی آموزش\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m train_acc, train_mae, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_trues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaler\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# اعتبارسنجی\u001b[39;00m\n\u001b[0;32m    147\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[68], line 98\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(preds, trues, scaler, close_idx)\u001b[0m\n\u001b[0;32m     95\u001b[0m dummy[:, close_idx] \u001b[38;5;241m=\u001b[39m preds\n\u001b[0;32m     96\u001b[0m pred_prices \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(dummy)[:, close_idx]\n\u001b[1;32m---> 98\u001b[0m \u001b[43mdummy\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m trues\n\u001b[0;32m     99\u001b[0m true_prices \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(dummy)[:, close_idx]\n\u001b[0;32m    101\u001b[0m direction_acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msign(pred_prices[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m-\u001b[39mpred_prices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39msign(true_prices[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m-\u001b[39mtrue_prices[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (10896,1) into shape (10896,)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# تنظیمات پایه\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# پارامترهای مدل\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50  # کاهش تعداد دوره‌ها\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "# کلاس Dataset اصلاح شده\n",
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.FloatTensor(self.sequences[idx]),\n",
    "            torch.FloatTensor([self.targets[idx]]).squeeze()  # اصلاح شکل تنسور هدف\n",
    "        )\n",
    "\n",
    "# مدل LSTM پایدار\n",
    "class StableLSTM(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze()\n",
    "\n",
    "# پیش‌پردازش داده با کنترل خطا\n",
    "def preprocess_data(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t')\n",
    "        \n",
    "        # تبدیل تاریخ و زمان\n",
    "        df['datetime'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'], \n",
    "                                      format='%Y.%m.%d %H:%M:%S')\n",
    "        df = df.sort_values('datetime')\n",
    "        \n",
    "        # انتخاب و نامگذاری ستون‌ها\n",
    "        price_data = df[['<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>', '<VOL>']]\n",
    "        price_data.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "        \n",
    "        # محاسبه اندیکاتورهای ساده\n",
    "        price_data['returns'] = price_data['close'].pct_change()\n",
    "        price_data['volatility'] = price_data['high'] - price_data['low']\n",
    "        price_data = price_data.dropna()\n",
    "        \n",
    "        # مقیاس‌گذاری\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(price_data)\n",
    "        \n",
    "        return scaled_data, scaler, price_data.columns\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"خطا در پردازش داده: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ایجاد دنباله‌ها با کنترل شکل داده\n",
    "def create_sequences(data, targets, seq_length):\n",
    "    try:\n",
    "        sequences = []\n",
    "        final_targets = []\n",
    "        for i in range(len(data)-seq_length):\n",
    "            sequences.append(data[i:i+seq_length])\n",
    "            final_targets.append(targets[i+seq_length])\n",
    "        return np.array(sequences), np.array(final_targets).reshape(-1, 1)  # اصلاح شکل targets\n",
    "    except Exception as e:\n",
    "        print(f\"خطا در ایجاد دنباله‌ها: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# محاسبه معیارها با کنترل ابعاد\n",
    "def calculate_metrics(preds, trues, scaler, close_idx=3):\n",
    "    try:\n",
    "        # اطمینان از شکل صحیح داده‌ها\n",
    "        preds = np.array(preds).reshape(-1)\n",
    "        trues = np.array(trues).reshape(-1)\n",
    "        \n",
    "        dummy = np.zeros((len(preds), scaler.n_features_in_))\n",
    "        dummy[:, close_idx] = preds\n",
    "        pred_prices = scaler.inverse_transform(dummy)[:, close_idx]\n",
    "        \n",
    "        dummy[:, close_idx] = trues\n",
    "        true_prices = scaler.inverse_transform(dummy)[:, close_idx]\n",
    "        \n",
    "        # محاسبه دقت جهتدار\n",
    "        direction_acc = np.mean(np.sign(pred_prices[1:]-pred_prices[:-1]) == \n",
    "                              np.sign(true_prices[1:]-true_prices[:-1])) * 100\n",
    "        mae = mean_absolute_error(true_prices, pred_prices)\n",
    "        rmse = np.sqrt(mean_squared_error(true_prices, pred_prices))\n",
    "        \n",
    "        return direction_acc, mae, rmse, pred_prices, true_prices\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"خطا در محاسبه معیارها: {str(e)}\")\n",
    "        return 0, 0, 0, [], []\n",
    "\n",
    "# آموزش مدل با گزارش‌دهی پیشرفته\n",
    "def train_and_report(model, train_loader, test_loader, scaler):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'test_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_acc': [],\n",
    "        'train_mae': [],\n",
    "        'test_mae': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # آموزش\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_trues = [], []\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_preds.extend(preds.detach().numpy())\n",
    "            train_trues.extend(y.numpy())\n",
    "        \n",
    "        # ارزیابی آموزش\n",
    "        train_acc, train_mae, _, _, _ = calculate_metrics(\n",
    "            train_preds, \n",
    "            train_trues,\n",
    "            scaler\n",
    "        )\n",
    "        \n",
    "        # اعتبارسنجی\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_preds, test_trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                preds = model(X)\n",
    "                test_loss += criterion(preds, y).item()\n",
    "                test_preds.extend(preds.numpy())\n",
    "                test_trues.extend(y.numpy())\n",
    "        \n",
    "        # ارزیابی آزمون\n",
    "        test_acc, test_mae, test_rmse, preds, trues = calculate_metrics(\n",
    "            test_preds,\n",
    "            test_trues,\n",
    "            scaler\n",
    "        )\n",
    "        \n",
    "        # ذخیره نتایج\n",
    "        history['train_loss'].append(train_loss/len(train_loader))\n",
    "        history['test_loss'].append(test_loss/len(test_loader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        history['test_mae'].append(test_mae)\n",
    "        \n",
    "        # چاپ گزارش\n",
    "        print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "        print(f'Train Loss: {history[\"train_loss\"][-1]:.4f} | Test Loss: {history[\"test_loss\"][-1]:.4f}')\n",
    "        print(f'Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%')\n",
    "        print(f'Train MAE: {train_mae:.2f} | Test MAE: {test_mae:.2f}')\n",
    "        print(f'Test RMSE: {test_rmse:.2f}')\n",
    "        \n",
    "        # نمایش نمونه پیش‌بینی‌ها\n",
    "        if epoch % 10 == 0 or epoch == EPOCHS-1:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(trues[:100], label='Actual Prices')\n",
    "            plt.plot(preds[:100], label='Predicted Prices')\n",
    "            plt.title(f'Epoch {epoch+1} - Sample Predictions')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    \n",
    "    # نمایش نمودارهای یادگیری\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['test_loss'], label='Test Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['test_acc'], label='Test Accuracy')\n",
    "    plt.title('Directional Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # بارگذاری و پیش‌پردازش داده\n",
    "    data, scaler, cols = preprocess_data('XAUUSD-VIP_M30.txt')\n",
    "    if data is None:\n",
    "        exit()\n",
    "    \n",
    "    close_idx = list(cols).index('close')\n",
    "    sequences, targets = create_sequences(data, data[:, close_idx], SEQ_LENGTH)\n",
    "    if sequences is None:\n",
    "        exit()\n",
    "    \n",
    "    # تقسیم داده\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_idx, test_idx in tscv.split(sequences):\n",
    "        train_seq, test_seq = sequences[train_idx], sequences[test_idx]\n",
    "        train_tgt, test_tgt = targets[train_idx], targets[test_idx]\n",
    "    \n",
    "    # ایجاد DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        PriceDataset(train_seq, train_tgt),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        PriceDataset(test_seq, test_tgt),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # ایجاد و آموزش مدل\n",
    "    model = StableLSTM(input_size=data.shape[1])\n",
    "    history = train_and_report(model, train_loader, test_loader, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
