{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c3d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec myenv in C:\\Users\\arman\\AppData\\Roaming\\jupyter\\kernels\\myenv\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name=myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff54512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arman\\Desktop\\New_Modeler\\env\\lib\\site-packages\\ta\\trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "C:\\Users\\arman\\AppData\\Local\\Temp\\ipykernel_18276\\1531219938.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  self.features = torch.tensor(self.features, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started...\n",
      "Epoch 1/30, Loss: 0.004599\n",
      "Epoch 2/30, Loss: 0.000048\n",
      "Epoch 3/30, Loss: 0.000036\n",
      "Epoch 4/30, Loss: 0.000030\n",
      "Epoch 5/30, Loss: 0.000033\n",
      "Epoch 6/30, Loss: 0.000034\n",
      "Epoch 7/30, Loss: 0.000037\n",
      "Epoch 8/30, Loss: 0.000049\n",
      "Epoch 9/30, Loss: 0.000032\n",
      "Epoch 10/30, Loss: 0.000039\n",
      "Epoch 11/30, Loss: 0.000036\n",
      "Epoch 12/30, Loss: 0.000032\n",
      "Epoch 13/30, Loss: 0.000042\n",
      "Epoch 14/30, Loss: 0.000033\n",
      "Epoch 15/30, Loss: 0.000034\n",
      "Epoch 16/30, Loss: 0.000030\n",
      "Epoch 17/30, Loss: 0.000037\n",
      "Epoch 18/30, Loss: 0.000036\n",
      "Epoch 19/30, Loss: 0.000025\n",
      "Epoch 20/30, Loss: 0.000030\n",
      "Epoch 21/30, Loss: 0.000035\n",
      "Epoch 22/30, Loss: 0.000027\n",
      "Epoch 23/30, Loss: 0.000033\n",
      "Epoch 24/30, Loss: 0.000027\n",
      "Epoch 25/30, Loss: 0.000034\n",
      "Epoch 26/30, Loss: 0.000032\n",
      "Epoch 27/30, Loss: 0.000027\n",
      "Epoch 28/30, Loss: 0.000027\n",
      "Epoch 29/30, Loss: 0.000036\n",
      "Epoch 30/30, Loss: 0.000028\n",
      "\n",
      "Final Evaluation on All Data:\n",
      "MAE: 6.6818, MSE: 83.8788\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ta import add_all_ta_features\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== 1. Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ =====\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    df.columns = ['date', 'time', 'open', 'high', 'low', 'close', 'tick_volume', 'volume', 'spread']\n",
    "    df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df = df[['open', 'high', 'low', 'close', 'tick_volume']]\n",
    "    df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"tick_volume\", fillna=True)\n",
    "    return df\n",
    "\n",
    "# ===== 2. Ø³Ø§Ø®Øª Ø¯ÛŒØªØ§Ø³Øª =====\n",
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, df, window=3):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        feature_cols = [col for col in df.columns if col != 'close']\n",
    "        scaler = MinMaxScaler()\n",
    "        df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        close_scaled = self.scaler_y.fit_transform(df[['close']])\n",
    "\n",
    "        for i in range(window, len(df_scaled) - 1):\n",
    "            self.features.append(df_scaled.iloc[i - window:i].values)\n",
    "            self.labels.append(close_scaled[i + 1][0])\n",
    "\n",
    "        self.features = torch.tensor(self.features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# ===== 3. Ù…Ø¯Ù„ LSTM =====\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# ===== 4. Ø¢Ù…ÙˆØ²Ø´ =====\n",
    "def train_model(model, dataloader, scaler_y, epochs=30, lr=1e-3):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        percent_errors = []\n",
    "        model.train()\n",
    "        for x, y in dataloader:\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            y_true_inv = scaler_y.inverse_transform(y.detach().numpy())\n",
    "            y_pred_inv = scaler_y.inverse_transform(pred.detach().numpy())\n",
    "            percent_error = np.mean(np.abs((y_true_inv - y_pred_inv) / y_true_inv)) * 100\n",
    "            percent_errors.append(percent_error)\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_percent_error = np.mean(percent_errors)\n",
    "        accuracy = 100 - avg_percent_error\n",
    "        print(f\"Epoch {epoch + 1:2d}/{epochs}, Loss: {avg_loss:.6f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# ===== 5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ =====\n",
    "def evaluate_model(model, dataset, title=\"Evaluation\"):\n",
    "    model.eval()\n",
    "    X, y = dataset[:]\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).numpy()\n",
    "        y_true = y.numpy()\n",
    "\n",
    "    y_true_inv = dataset.scaler_y.inverse_transform(y_true)\n",
    "    preds_inv = dataset.scaler_y.inverse_transform(preds)\n",
    "\n",
    "    mse = np.mean((preds_inv - y_true_inv) ** 2)\n",
    "    mae = np.mean(np.abs(preds_inv - y_true_inv))\n",
    "    accuracy = 100 - (np.mean(np.abs((preds_inv - y_true_inv) / y_true_inv)) * 100)\n",
    "\n",
    "    print(f\"\\nðŸ“Š {title}:\")\n",
    "    print(f\"MAE: {mae:.4f}, MSE: {mse:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Ù†Ù…ÙˆØ¯Ø§Ø±\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y_true_inv, label='Actual', linewidth=1.5)\n",
    "    plt.plot(preds_inv, label='Predicted', linewidth=1.5)\n",
    "    plt.title(f\"{title} - Actual vs Predicted Close Prices\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ===== 6. Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ =====\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data(\"XAUUSD-VIP_M30.txt\")\n",
    "\n",
    "    # ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡\n",
    "    split_ratio = 0.8\n",
    "    split_index = int(len(df) * split_ratio)\n",
    "    df_train = df.iloc[:split_index]\n",
    "    df_test = df.iloc[split_index:]\n",
    "\n",
    "    train_dataset = PriceDataset(df_train)\n",
    "    test_dataset = PriceDataset(df_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    input_size = train_dataset.features.shape[2]\n",
    "    model = LSTMModel(input_size=input_size)\n",
    "\n",
    "    print(\"ðŸ“Œ Training Started...\")\n",
    "    train_model(model, train_loader, train_dataset.scaler_y)\n",
    "\n",
    "    evaluate_model(model, train_dataset, \"Train Evaluation\")\n",
    "    evaluate_model(model, test_dataset, \"Test Evaluation\")\n",
    "\n",
    "    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„\n",
    "    torch.save(model.state_dict(), \"price_predictor.pth\")\n",
    "    print(\"\\nâœ… Model saved to price_predictor.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
